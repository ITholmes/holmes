# 大数据分析可视化整体流程构建部署

> 以 学习 为场景，不断进步。



# 1. 获取数据

日志、爬虫、业务系统汇总等等。



暂时将图片上传到 服务器。

# 2. 将图片上传到 `Hadoop HDFS` 中

先给每台节点 安装 Python环境 。

将数据导入到HDFS中：

```python
import os 
from subprocess import call

def upload_to_hdfs(local_file_path, hdfs_file_path):
    command = "hadoop fs -put {} {}".format(local_file_path, hdfs_file_path)
    print("command is {}".format(command))
    call(command, shell=True)

local_image_dir = "images"
hdfs_image_dir = "/hadoop/test/images"

for image_file in os.listdir(local_image_dir):
    if image_file.endswith(".jpg") or image_file.endswith(".png"):
        upload_to_hdfs(os.path.join(local_image_dir, image_file), hdfs_image_dir)
```





# 3.  Spark  和 Flink 



使用 Spark 或 Flink 进行图片分析

